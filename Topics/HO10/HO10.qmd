---
title: "Geospatial Analysis"
author: "Wan Kee"
date: "22 February 2024"
date-modified: "last-modified"
execute: 
  eval: true
  echo: true 
  warning: false
  message: false
  error: true
  freeze: true # git add_freeze/
---

# 1. Learning Objective

A choropleth map is a thematic map composed of **coloured polygons** and is used to represent statistical data using the color mapping symbology technique.

Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.

-   Plot choropleth maps using tmap package

# 2. Import Packages

```{r}
pacman::p_load(tidyverse, sf, tmap, psych)
```

# 3. Load Data

::: panel-tabset
## Master Plan Subzone

`mpsz` is the Master Plan 2014 Subzone Boundary in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014. `st_read()` function of sf package to import the MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame.

```{r}
mpsz <- st_read(dsn = "data/geospatial", 
                layer = "MP14_SUBZONE_WEB_PL")
```

```{r}
mpsz
```

## Population

`pop` is the Singapore Residents by Planning Area/Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.

```{r}
pop <- read_csv("data/aspatial/respopagesextod2011to2020.csv")
glimpse(pop)
```
:::

# 4. Prepare Data

::: panel-tabset
## Recode

The following attributes will be derived:

YOUNG: Age group `0_to_4` and `20_to_24` ECONOMY ACTIVE: Age group `25_to_29` and `60_to_64` AGED: Age group `65_and_above` TOTAL: All age group DEPENDENCY: Ratio between YOUNG and AGED : ECONOMIC ACTIVE

```{r}
pop2020 <- pop %>%
  filter(Time == 2020) %>%
  group_by(PA, SZ, AG) %>%
  summarise(POP = sum(Pop)) %>%
  ungroup() %>%
  pivot_wider(names_from = AG, values_from = POP) %>%
  mutate(YOUNG = rowSums(.[3:6]) + rowSums(.[12])) %>%
  mutate(ECONOMY_ACTIVE = rowSums(.[7:11]) + rowSums(.[13:15]))%>%
  mutate(AGED = rowSums(.[16:21])) %>%
  mutate(TOTAL = rowSums(.[3:21])) %>%
  mutate(DEPENDENCY = (YOUNG + AGED)/ECONOMY_ACTIVE) %>%
  select(PA, SZ, YOUNG, ECONOMY_ACTIVE, AGED, TOTAL, DEPENDENCY)
glimpse(pop2020)
```

```{r}
describe(pop2020)
```

## Uppercase

`PA` and `SZ` of `pop2020` and `SUBZONE_N` and `PLN_AREA_N` of `mpsz`are standardized to uppercase.

```{r}
pop2020 <- pop2020 %>%
  mutate_at(.vars = vars(PA, SZ), .funs = funs(toupper)) %>%
  filter(ECONOMY_ACTIVE > 0)
describe(pop2020)
```

## Left Join

`pop2020` and `mpsz` are joined using `SZ` and `SUBZONE_N`.

```{r}
mpszpop2020 <- left_join(mpsz, pop2020,
                         by = c("SUBZONE_N" = "SZ"))
glimpse(mpszpop2020)
```
:::

::: {.callout-note collapse="true"}
# Save Point

```{r}
write_rds(mpszpop2020, "data/mpszpop2020.rds")
```
:::

# 5. Choropleth Map

::: {.callout-note collapse="true"}
## Load Point

```{r}
mpszpop2020 <- readRDS("data/mpszpop2020.rds")
```
:::

## qtm()

`qtm()` plots a quick thematic map and is a convenient wrapper of the main plotting method. The `fill` argument is either a colour or a data variable to draw a choropleth. The disadvantge of `qtm()` makes aesthetics of individual layers harder to control.

```{r}
tmap_mode("plot")
qtm(mpszpop2020, fill = "DEPENDENCY")
```

## tmap()

The basic building block of tmap is `tm_shape()` followed by the layer elements `tm_shape()` to define the input data and `tm_polygons()` to draw the planning subzone polygons.

Note that `tm_polygons()` is a wrapper of `tm_fill()` and `tm_border()`. `tm_fill()` shades the polygons by using the default colour scheme and `tm_borders()` adds the borders of the shapefile onto the choropleth map where the `alpha` argument is used to define transparency number between 0 (totally transparent) and 1 (default; not transparent).

tmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty, quantile, kmeans, hclust, bclust, fisher, and jenks. The default interval binning used to draw the choropleth map is **pretty** and the default colour scheme is YlOrRd of ColorBrewer. By default, Missing value will be shaded in grey.

::: panel-tabset
### pretty

The **pretty** style chooses a number of breaks not necessarily equal to n using pretty, but likely to be legible.

```{r}
tm_shape(mpszpop2020)+
  tm_polygons("DEPENDENCY")
```

### quantile

The **quantile** style provides quantile breaks.

```{r}
tm_shape(mpszpop2020)+
  tm_fill("DEPENDENCY",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5)
```

### kmeans

The **kmeans** style uses kmeans to generate the breaks; it may be anchored using `set.seed`.

```{r}
tm_shape(mpszpop2020)+
  tm_fill("DEPENDENCY",
          n = 5,
          style = "kmeans") +
  tm_borders(alpha = 0.5)
```

### bclust

The **hclust** style uses hclust to generate the breaks using hierarchical clustering. The **bclust** style uses bclust to generate the breaks using bagged clustering.

```{r}
tm_shape(mpszpop2020)+
  tm_fill("DEPENDENCY",
          n = 5,
          style = "bclust") +
  tm_borders(alpha = 0.5)
```

### fisher

The **fisher** style uses the algorithm proposed by W. D. Fisher (1958) and discussed by Slocum et al. (2005) as the Fisher-Jenks algorithm. This style will subsample by default for more than 3000 observations.

```{r}
tm_shape(mpszpop2020)+
  tm_fill("DEPENDENCY",
          n = 5,
          style = "fisher") +
  tm_borders(alpha = 0.5)
```

### jenks

`jenks` is a quantile data classification that used 5 classes. The jenks style has been ported from Jenks' code, and has been checked for consistency with ArcView, ArcGIS, and MapInfo

```{r}
tm_shape(mpszpop2020)+
  tm_fill("DEPENDENCY",
          n = 5,
          style = "jenks") +
  tm_borders(alpha = 0.5)
```
:::

## Breaks

Breaks are computed internally or set explicitly by means of the breaks argument to the `tm_fill()`. It is a good practice to obtain descriptive statistics on the variable before setting the break points.

```{r}
summary(mpszpop2020$DEPENDENCY)
```

Based on the output, the break points are set at 0.60, 0.70, 0.80, and 0.90. In addition, a minimum and maximum will also be set at 0 and 100. Therefore, the breaks vector is c(0, 0.60, 0.70, 0.80, 0.90, 1.00).

```{r}
tm_shape(mpszpop2020)+
  tm_fill("DEPENDENCY",
          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +
  tm_borders(alpha = 0.5)
```

```{r}
tm_shape(mpszpop2020)+
  tm_fill("DEPENDENCY", 
          style = "quantile", 
          palette = "Blues",
          title = "Dependency ratio") +
  tm_layout(main.title = "Distribution of Dependency Ratio by planning subzone",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2) +
  tm_credits("Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\n and Population data from Department of Statistics DOS", 
             position = c("left", "bottom"))
```

## Multiple Choropleth Plots

```{r}
tm_shape(mpszpop2020)+ 
  tm_polygons(c("YOUNG","AGED"),
          style = c("pretty", "pretty"), 
          palette = list("Blues","Purples")) +
  tm_layout(legend.position = c("right", "bottom"))
```

```{r}
tm_shape(mpszpop2020)+ 
  tm_polygons(c("YOUNG","AGED"),
          style = c("quantile", "quantile"), 
          palette = list("Blues","Purples")) +
  tm_layout(legend.position = c("right", "bottom"))
```

## Group-by Variable

```{r}
tm_shape(mpszpop2020) +
  tm_fill("DEPENDENCY",
          style = "quantile",
          palette = "Blues",
          thres.poly = 0) + 
  tm_facets(by="REGION_N", 
            free.coords=TRUE, 
            drop.shapes=FALSE) +
  tm_layout(legend.show = FALSE,
            title.position = c("center", "center"), 
            title.size = 20) +
  tm_borders(alpha = 0.5)
```

```{r}
tm_shape(mpszpop2020[mpszpop2020$REGION_N=="CENTRAL REGION", ])+
  tm_fill("DEPENDENCY", 
          style = "quantile", 
          palette = "Blues", 
          legend.hist = TRUE, 
          legend.is.portrait = TRUE,
          legend.hist.z = 0.1) +
  tm_layout(legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE) +
  tm_borders(alpha = 0.5)
```

# 6. Geospatial Data Point

Visualizing geospatial point data typically involves plotting points on a map to represent locations or events. Using the mapping library to create a map and add the data points as layers, the map appearance can be customized to enhance visualization, such as background, colors, and labels.

Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon.

# 7. Load Data

SGPools

`SGPools` contains the locations of Singapore outlets and branches and their respective winnings.

```{r}
sgpools <- read_csv("data/aspatial/SGPools_svy21.csv")
glimpse(sgpools)
```

# 8. Prepare Data

`st_as_sf()` converts sgpools data frame into a simple feature data frame. The `coords` argument defines the x-coordinates and y-coordinates. The `crs` argument specifies the coordinates system in epsg format where EPSG: 3414 is Singapore SVY21 Projected Coordinate System.

```{r}
sgpools_sf <- st_as_sf(sgpools, 
                       coords = c("XCOORD", "YCOORD"),
                       crs= 3414)
```

# 9. Interactive Geospatial Point Map

`tm_bubbles()` adds bubble symbols to the map and are often used to represent point data.

The `size` argument specifies the attribute used to determine the size of the bubbles. It can take on a **numeric value** as a standard size or a **numeric attribute** where the size will be proportional to the values of the "Gp1Gp2 Winnings" attribute.

The `col` argument specifies the color of the bubbles. It can be a **colour value** or a **categorical attribute**.

```{r}
tmap_mode("view")

tm_shape(sgpools_sf) +
  tm_bubbles(col = "OUTLET TYPE",
             size = "Gp1Gp2 Winnings",
             border.col = "black",
             border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,12))
```

`tm_facets()` divides the map into multiple facets based on the specified attribute. Each unique value of the attribute will result in a separate facet.

The `by` argument specifies the attribute used to create facets. Each unique value of the "OUTLET TYPE" attribute will result in a separate facet.

The `nrow` argument specifies the number of rows in the facet grid. Where nrow = 1, all facets will be arranged in a single row.

The `sync` argument specifies whether the scales of the facets should be synchronized. When set to TRUE, the scales (e.g., zoom levels) of all facets will be synchronized, allowing for easy comparison between facets.

```{r}
tm_shape(sgpools_sf) +
  tm_bubbles(col = "OUTLET TYPE", 
          size = "Gp1Gp2 Winnings",
          border.col = "black",
          border.lwd = 1) +
  tm_facets(by= "OUTLET TYPE",
            nrow = 1,
            sync = TRUE) +
  tm_view(set.zoom.limits = c(11,12))
```

# 10. Geospatial Analytical Map

Geospatial analytical maps involve the visualization and analysis of spatial data to reveal patterns, trends, and relationships within a geographic context. These maps are designed to provide insights into spatial distributions and variations, allowing for better understanding and interpretation of data. Some common types of geospatial analytical maps include choropleth maps, rate maps, percentile maps, and boxmaps.

# 11. Import Data

`NGA_wp` is a polygon feature data frame providing information on water point of Nigeria at the LGA level.

```{r}
NGA_wp <- read_rds("data/rds/NGA_wp.rds")
```

# 12. Choropleth Maps

Choropleth maps use color shading to represent variations in data values across geographic regions. Each region is shaded based on the value of a specific variable, such as population density, average income, or disease prevalence. Choropleth maps are useful for visualizing spatial patterns and disparities in data.

```{r}
tmap_mode("view")

p1 <- tm_shape(NGA_wp) +
  tm_fill("wp_functional",
          n = 10,
          style = "equal",
          palette = "Blues") +
  tm_borders(lwd = 0.1,
             alpha = 1) +
  tm_layout(main.title = "Distribution of functional water point by LGAs",
            legend.outside = FALSE)

p2 <- tm_shape(NGA_wp) +
  tm_fill("total_wp",
          n = 10,
          style = "equal",
          palette = "Blues") +
  tm_borders(lwd = 0.1,
             alpha = 1) +
  tm_layout(main.title = "Distribution of total water point by LGAs",
            legend.outside = FALSE)

tmap_arrange(p2, p1, nrow = 1)
```

# 13. Rate Maps

**Rate maps** are a type of choropleth map that display rates or proportions per unit area. They are commonly used to visualize rates of occurrence or density of phenomena, such as crime rates, disease incidence, or population density. Rate maps often involve normalizing raw counts by a population or area size to allow for meaningful comparisons between different regions.

`mutate()` from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.

```{r}
NGA_wp <- NGA_wp %>%
  mutate(pct_functional = wp_functional/total_wp) %>%
  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)

tm_shape(NGA_wp) +
  tm_fill("pct_functional",
          n = 10,
          style = "equal",
          palette = "Blues",
          legend.hist = TRUE) +
  tm_borders(lwd = 0.1,
             alpha = 1) +
  tm_layout(main.title = "Rate map of functional water point by LGAs",
            legend.outside = TRUE)
```

# 14. Percentile Maps

**Percentile maps** divide the data into equal intervals based on percentiles and assign each interval a unique color or shading. This type of map is useful for identifying relative rankings or distributions of values within a dataset. Percentile maps highlight areas with high or low values relative to the entire dataset and can be effective for comparing distributions across different regions.

The data preparation as below:

::: panel-tabset
## Missing Data

`drop_na()` excludes records with NA.

```{r}
NGA_wp <- NGA_wp %>%
  drop_na()
```

## Cumulative Probability

Create customised classification by defining percentile classes where `percent` is c(0,.01,.1,.5,.9,.99,1).

During variables extraction, the geometry is extracted but base R functions cannot deal with the geometry. To prevent an error from `quantile()`, `st_set_geomtry()` is set to NULL to drop geomtry field.

```{r}
percent <- c(0,.01,.1,.5,.9,.99,1)
var <- NGA_wp["pct_functional"] %>%
  st_set_geometry(NULL)
quantile(var[,1], percent)
```

## get.var function

We will write an R function `get.var` to extract a variable (wp_nonfunctional) as a vector out of an sf data.frame.

The arguments are `vname` for variable name and `df` as the name of sf data frame It returns `v`, the vector with values.

```{r}
get.var <- function(vname,df) {
  v <- df[vname] %>% 
    st_set_geometry(NULL)
  v <- unname(v[,1])
  return(v)
}
```
:::

```{r}
percentmap <- function(vnam, df, legtitle=NA, mtitle="Percentile Map"){
  percent <- c(0,.01,.1,.5,.9,.99,1)
  var <- get.var(vnam, df)
  bperc <- quantile(var, percent)
  tm_shape(df) +
  tm_polygons() +
  tm_shape(df) +
     tm_fill(vnam,
             title=legtitle,
             breaks=bperc,
             palette="Blues",
          labels=c("< 1%", "1% - 10%", "10% - 50%", "50% - 90%", "90% - 99%", "> 99%"))  +
  tm_borders() +
  tm_layout(main.title = mtitle, 
            title.position = c("right","bottom"))
}

percentmap("total_wp", NGA_wp)
```

# 15. Boxmaps

Boxmaps, also known as box plot maps, are a spatial representation of box plots. They display summary statistics of a variable (e.g., median, quartiles, outliers) for different geographic areas. Each area is represented by a box plot, with the length of the box indicating the interquartile range (IQR) and the median value shown as a horizontal line within the box. Boxmaps provide a compact visualization of spatial variability and distribution of data.

The data preparation as below:

::: panel-tabset
## boxbreak function

`boxbreak` is an R function that creating break points for a box map. The arguments `v` indicates vector with observations, `multi` is the multiplier for IQR (default 1.5). The function returns `bb`, a vector with 7 break points compute quartile and fences.

```{r}
boxbreaks <- function(v,mult=1.5) {
  qv <- unname(quantile(v))
  iqr <- qv[4] - qv[2]
  upfence <- qv[4] + mult * iqr
  lofence <- qv[2] - mult * iqr
  # initialize break points vector
  bb <- vector(mode="numeric",length=7)
  # logic for lower and upper fences
  if (lofence < qv[1]) {  # no lower outliers
    bb[1] <- lofence
    bb[2] <- floor(qv[1])
  } else {
    bb[2] <- lofence
    bb[1] <- qv[1]
  }
  if (upfence > qv[5]) { # no upper outliers
    bb[7] <- upfence
    bb[6] <- ceiling(qv[5])
  } else {
    bb[6] <- upfence
    bb[7] <- qv[5]
  }
  bb[3:5] <- qv[2:4]
  return(bb)
}
```

## get.var function

`get.var` is a function to extract a variable as a vector out of an sf data frame. The arguments `vname` is the variable name and `df` is the name of sf data frame. It returns `v`, a vector with values.

```{r}
get.var <- function(vname,df) {
  v <- df[vname] %>% st_set_geometry(NULL)
  v <- unname(v[,1])
  return(v)
}
```

```{r}
var <- get.var("wp_nonfunctional", NGA_wp) 
boxbreaks(var)
```
:::

```{r}
boxmap <- function(vnam, df, legtitle=NA,
                   mtitle="Box Map", mult=1.5){
  var <- get.var(vnam,df)
  bb <- boxbreaks(var)
  
  tm_shape(df) +
    tm_polygons() +
  tm_shape(df) +
     tm_fill(vnam,title=legtitle,
             breaks=bb,
             palette="Blues",
             labels = c("lower outlier", "< 25%", "25% - 50%", "50% - 75%", "> 75%", "upper outlier")) +
  tm_borders() +
  tm_layout(main.title = mtitle, 
            title.position = c("left", "top"))
}

tmap_mode("plot")
boxmap("wp_nonfunctional", NGA_wp)
```

# 16. Isohyet Map

An **isohyet map** is a type of thematic map that represents lines of equal precipitation on a geographic area. These lines connect points of equal rainfall or precipitation amounts over a given period of time, such as a year or a month. Isohyet maps are commonly used in meteorology, climatology, and hydrology to visualize and analyze spatial variations in precipitation across a region.

The term "isohyet" is derived from Greek roots "iso," meaning equal, and "hyetos," meaning rainfall or precipitation. Isohyet maps typically display isohyetal lines, also known as **isohyets**, which connect areas with the same precipitation values. The spacing between isohyetal lines represents the amount of precipitation change between adjacent lines, with closer spacing indicating steeper gradients in precipitation levels.

## 16.1 Import Packages

`viridis` is a colour library. `terra` create grid (also known as raster) objects as the input and output of spatial interpolation. `gstat` performs spatial interpolation (geostatistics) to convert point to gradient; useful for spatial and spatio-temporal geostatistical modelling, prediction and simulation. `automap` performs automatic variogram modelling and kriging interpolation.

```{r}
pacman::p_load(sf, terra, gstat, tmap, viridis, tidyverse, automap)
```

## 16.2 Import Data

`rfstations` provides location information of existing rainfall stations in Singapore. The data is downloaded from Meteological Service Singapore.

```{r}
rfstations <- read.csv("data/aspatial/RainfallStation.csv")
glimpse(rfstations)
```

`rfdata` provides weather data are rainfall stations for the month February, 2024. The data is also downloaded from Meteological Service Singapore. The `Latitude` and `Longitude` range shows WGS84 coordinate system and is developed by Greenwich Meridian.

`read_csv()` of readr package is used to import DAILYDATA_202402.csv. The output object `rfdata` is in tibble data.frame format.

```{r}
rfdata <- read_csv("data/aspatial/DAILYDATA_202402.csv")
glimpse(rfdata)
```

`mpsz2019` contains planning subzone boundary of URA Master Plan 2019. It is downloaded from data.gov.sg. The original data is in kml format.

```{r}
mpsz2019 <- st_read(dsn = "data/geospatial",
                    layer = "MPSZ-2019") %>% 
  st_transform(crs = 3414)
mpsz2019
```

## 16.3 Prepare Data

Aggregate rainfall at month level (variability over empty value)

`select()` of `dplyr` package is used to retain column 1 and 5 of the input data. `group_by()` and `summarise()` of `dplyr` package are used to compute the total monthly rainfall from Daily Rainfall Total (mm) field. The output is stored in a new field called **MONTHSUM**.

```{r}
rfdata <- rfdata %>% 
  select(c(1,5)) %>% 
  group_by(Station) %>% 
  summarise(MONTHSUM = sum(`Daily Rainfall Total (mm)`)) %>% 
  ungroup()
glimpse(rfdata)
```

`rfdata` (43 rows) is the reference data for `left_join` with `rfstations` (63 rows) and joining with default `by = join_by(Station)`. `left_join()` of `dplyr` is used to join `rfstations` to `rfdata`.

```{r}
rfdata <- rfdata %>% 
  left_join(rfstations)
glimpse(rfdata)
```

`st_as_sf()` of `sf` package is used to convert `rfdata` into a simple feature data.frame object called `rfdata_sf`. `st_transform` of `sf` package converts the position (degrees) to geometry (metres); transforming the source data from wgs84 to svy21 projected coordinates system. SVY21 is the official projected coordinates of Singapore and the EPSG code of SVY21 is 3414.

For `coords` argument, it is important to map the X (i.e. Longitude) first, then follow by the Y (i.e. Latitude). `crs = 4326` indicates that the source data is in wgs84 coordinates system.

```{r}
rfdata_sf <- st_as_sf(rfdata, coords = c("Longitude", "Latitude"), # xaxis then yaxis
                      crs = 4326) %>% 
  st_transform(crs = 3414)
```

## 16.4 Spatial Interpolation

In order to prepare an isohyet map, spatial interpolation will be used. **Spatial interpolation** is the process of using points with known values to estimate values at other unknown points. For example, to make a rainfall above, we will not find enough evenly spread weather stations to cover the entire region. Spatial interpolation can estimate the rainfall at locations without recorded data by using known rainfall readings at nearby weather stations (see figure_temperature_map). This type of interpolated surface is often called a geostatistical surface. Elevation data, temperature, property prices, air quality index and population density are other types of data that can be computed using interpolation.

There are many interpolation methods. In this hands-on exercise, two widely used spatial interpolation methods called **Inverse Distance Weighting (IDW)** and **kriging** will be introduce. If you are looking for additional interpolation methods, please refer to the ‘Further Reading’ section at the end of this topic.

### 16.4.1 Rainfall Distribution

`tmap` functions are used to create a quantitative dot map of rainfall distribution by rainfall station in Singaspore. `tmap_options(check.and.fix = TRUE)` bypass topological errors. `tm_borders()` provides subzone borders with no fill. `tm_polygons()` is a combination of `tm_borders()` and `tm_fill()`.

```{r}
tmap_options(check.and.fix = TRUE)

tmap_mode("view")

tm_shape(mpsz2019)+
  tm_borders()+
tm_shape(rfdata_sf)+
  tm_dots(col = "MONTHSUM")

# tmap_mode("plot")
```

### 16.4.2 Create gstat object

In order to perform spatial interpolation by using gstat, we first need to create an object of class called `gstat`, using a function also called `gstat`. A **gstat object** contains all necessary information to conduct spatial interpolation, namely:

-   **Model definition**
-   **Calibration data**

Based on its arguments, the gstat function “understands” what type of interpolation model:

-   No variogram model → IDW
-   Variogram model, no covariates → Ordinary Kriging
-   Variogram model, with covariates → Universal Kriging

The complete **decision tree** of gstat, including several additional methods which we are not going to use, is shown in the figure below.

![](/Topics/HO11/images/gstat_decision_tree.png)

`rast()` of `terra` package create a grid data object. read the bounding box values; take the difference of xmax and xmin, and ymax and ymin.

**Bounding box: xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33**

If raster is 50m or 100m, divide by the difference.

```{r}
grid <- terra::rast(mpsz2019, nrows = 690, ncols = 1075)
grid
```

A list `xy` will be created by using `xyFromCell()` of `terra` package. `xyFromCell()` gets coordinates of the center of raster cells for a row, column, or cell number of a SpatRaster. Or get row, column, or cell numbers from coordinates or from each other.

```{r}
xy <- terra::xyFromCell(grid, 1:ncell(grid))
head(xy)
```

### 16.4.3 Create sf object

```{r}
coop <- st_as_sf(as.data.frame(xy), 
                 coords = c("x", "y"),
                 crs = st_crs(mpsz2019))
coop <- st_filter(coop, mpsz2019)
head(coop)
```

## 16.5 Inverse Distance Weighted (IDW)

In the IDW interpolation method, the sample points are weighted during interpolation such that the **influence** of one point relative to another **declines with distance** from the unknown point you want to create.

![](/Topics/HO11/images/idw.png)

**Weighting** is assigned to sample points through the use of a **weighting coefficient** that controls how the weighting influence will drop off as the distance from new point increases. The greater the weighting coefficient, the less the effect points will have if they are far from the unknown point during the interpolation process. As the coefficient increases, the value of the unknown point approaches the value of the nearest observational point.

It is important to notice that the IDW interpolation method also has some disadvantages: the **quality** of the interpolation result can decrease, if the **distribution** of sample data points is **uneven**. Furthermore, maximum and minimum values in the interpolated surface can only occur at sample data points. This often results in small peaks and pits around the sample data points.

We are going to use **three parameters** of the gstat function: formula:

`g = gstat(formula = annual ~ 1, data = rainfall)`

-   The prediction “formula” specifying the dependent and the independent variables (covariates) data
-   The calibration data model
-   The variogram model

A **formula** object is created using the \~ operator, which separates names of dependent variables (to the left of the \~ symbol) and independent variables (to the right of the \~ symbol). Writing 1 to the right of the \~ symbol, as in \~ 1, means that there are no independent variables38.

Calculate inverse weighted `nmax` where 15 neighbours are considered.

```{r}
res <- gstat(formula = MONTHSUM ~ 1, 
             locations = rfdata_sf, 
             nmax = 5,
             set = list(idp = 0))
```

Calculate the predicted values using interpolation

After defining the model, `predict()` is used to interpolate, i.e., to calculate predicted values.

The `predict` function accepts:

-   A raster—stars object, such as dem
-   A model—gstat object, such as g

The raster serves for two purposes:

-   Specifying the locations where we want to make predictions (in all methods)
-   Specifying covariate values (in Universal Kriging only)

```{r}
resp <- predict(res, coop)
glimpse(resp)
```
```{r}
resp$x <- st_coordinates(resp)[,1]
resp$y <- st_coordinates(resp)[,2]
resp$pred <- resp$var1.pred

pred <- terra::rasterize(resp, grid, 
                         field = "pred", 
                         fun = "mean")
```

```{r}
tmap_options(check.and.fix = TRUE)
tmap_mode("plot")
tm_shape(pred) + 
  tm_raster(alpha = 0.6, 
            palette = "viridis")
```
# 16.6 Kriging

Kriging is one of several methods that use a limited set of sampled data points to estimate the value of a variable over a continuous spatial field. An example of a value that varies across a random spatial field might be total monthly rainfall over Singapore. It differs from Inverse Distance Weighted Interpolation discussed earlier in that it uses the spatial correlation between sampled points to interpolate the values in the spatial field: the interpolation is based on the spatial arrangement of the empirical observations, rather than on a presumed model of spatial distribution. Kriging also generates estimates of the uncertainty surrounding each interpolated value.

In a general sense, the kriging weights are calculated such that points nearby to the location of interest are given more weight than those farther away. Clustering of points is also taken into account, so that clusters of points are weighted less heavily (in effect, they contain less information than single points). This helps to reduce bias in the predictions.

The kriging predictor is an “optimal linear predictor” and an exact interpolator, meaning that each interpolated value is calculated to minimize the prediction error for that point. The value that is generated from the kriging process for any actually sampled location will be equal to the observed value at this point, and all the interpolated values will be the Best Linear Unbiased Predictors (BLUPs).

Kriging will in general not be more effective than simpler methods of interpolation if there is little spatial autocorrelation among the sampled data points (that is, if the values do not co-vary in space). If there is at least moderate spatial autocorrelation, however, kriging can be a helpful method to preserve spatial variability that would be lost using a simpler method (for an example, see Auchincloss 2007, below).

Kriging can be understood as a two-step process:

first, the spatial covariance structure of the sampled points is determined by fitting a variogram; and
second, weights derived from this covariance structure are used to interpolate values for unsampled points or blocks across the spatial field.
Kriging methods require a variogram model. A variogram (sometimes called a “semivariogram”) is a visual depiction of the covariance exhibited between each pair of points in the sampled data. For each pair of points in the sampled data, the gamma-value or “semi-variance” (a measure of the half mean-squared difference between their values) is plotted against the distance, or “lag”, between them. The “experimental” variogram is the plot of observed values, while the “theoretical” or “model” variogram is the distributional model that best fits the data.

Firstly, we will calculate and examine the empirical variogram by using variogram() of gstat package. The function requires two arguments:

formula, the dependent variable and the covariates (same as in gstat, see Section 12.2.1)
data, a point layer with the dependent variable and covariates as attributes
as shown in the code chunk below.

```{r}
v <- variogram(MONTHSUM ~ 1, 
               data = rfdata_sf)
plot(v)
```

We can then compare the plot with the theoretical models below.

With reference to the comparison above, am empirical variogram model will be fitted by using `fit.variogram()` of gstat package as shown in the code chunk below.

Plot statistics and fit into a model, followed by interpolation Based on `model` where selection is dependent on `psill`, `model`, `range`, and `nugget` `range` 900m or 5000m is the search radius.

```{r}
fv <- fit.variogram(object = v, model = vgm(psill = 0.5, model = "Sph",
                                            range = 5000, nugget = 0.1))
fv
```

We can visualise how well the observed data fit the model by plotting fv using the code chunk below.

```{r}
plot(v, fv)
```

The plot above reveals that the empirical model fits rather well. In view of this, we will go ahead to perform spatial interpolation by using the newly derived model as shown in the code chunk below.

```{r}
k <- gstat(formula = MONTHSUM ~ 1, 
           data = rfdata_sf, 
           model = fv)
k
```

predict() of gstat package will be used to estimate the unknown grids by using the code chunk below. resp is a sf tibble data.frame with point features.

```{r}
resp <- predict(k, coop)
```

```{r}
resp$x <- st_coordinates(resp)[,1]
resp$y <- st_coordinates(resp)[,2]
resp$pred <- resp$var1.pred
resp$pred <- resp$pred
resp
```

```{r}
kpred <- terra::rasterize(resp, grid, 
                         field = "pred")
kpred
```


The output object kpred is in SpatRaster object class with a spatial resolution of 50m x 50m. It consists of 1075 columns and 690 rows and in SVY21 projected coordinates system.

# 16.7 Mapping the interpolated rainfall raster

tmap functions are used to map the interpolated rainfall raster (i.e. kpred) by using the code chunk below.

```{r}
tmap_options(check.and.fix = TRUE)
tmap_mode("plot")
tm_shape(kpred) + 
  tm_raster(alpha = 0.6, 
            palette = "viridis",
            title = "Total monthly rainfall (mm)") +
  tm_layout(main.title = "Distribution of monthly rainfall, Feb 2024",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2)
```

# 16.8 Automatic Variogram Modelling

autofirVariogram() of automap package can be used to perform varigram modelling as shown in the code chunk below.

```{r}
v_auto <- autofitVariogram(MONTHSUM ~ 1, 
                           rfdata_sf)
plot(v_auto)
```

```{r}
v_auto
```

```{r}
k <- gstat(formula = MONTHSUM ~ 1, 
           model = v_auto$var_model,
           data = rfdata_sf)
k
```

```{r}
resp <- predict(k, coop)
```

```{r}
resp$x <- st_coordinates(resp)[,1]
resp$y <- st_coordinates(resp)[,2]
resp$pred <- resp$var1.pred
resp$pred <- resp$pred

kpred <- terra::rasterize(resp, grid, 
                         field = "pred")
```

```{r}
tmap_options(check.and.fix = TRUE)
tmap_mode("plot")
tm_shape(kpred) + 
  tm_raster(alpha = 0.6, 
            palette = "viridis",
            title = "Total monthly rainfall (mm)") +
  tm_layout(main.title = "Distribution of monthly rainfall, Feb 2024",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2)
```

References: 

https://isss608-vaa-demo.netlify.app/in-class_ex/in-class_ex07/in-class_ex07-isomap

Olea, Ricardo A. (2006-07) “A six-step practical approach to semivariogram modeling”, Stochastic Environmental Research and Risk Assessment, 2006-07, Vol.20 (5), p.307-318. SMU e-journal.
